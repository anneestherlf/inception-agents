# Importa√ß√µes necess√°rias (incluindo a do Gemini)
import streamlit as st
import pandas as pd
import gspread
import plotly.express as px
from dotenv import load_dotenv
import google.generativeai as genai

# Carrega as chaves do arquivo .env
load_dotenv()

# --- CONFIGURA√á√ÉO DA P√ÅGINA ---
st.set_page_config(
    page_title="NVIDIA Inception LatAm Dashboard",
    page_icon="ü§ñ",
    layout="wide"
)

# --- FUN√á√ïES DE BACKEND ---

# Conecta com o Google Sheets e busca os dados
@st.cache_data(ttl=600)
def carregar_dados():
    try:
        # Para rodar localmente
        gc = gspread.service_account(filename='credentials.json')
    except FileNotFoundError:
        # Para deploy no Streamlit Cloud, usando os Secrets
        gc = gspread.service_account_from_dict(st.secrets["gcp_service_account"])
        
    planilha = gc.open("Base de Startups NVIDIA")
    aba = planilha.sheet1
    dados = aba.get_all_records()
    df = pd.DataFrame(dados)
    df['Ano de Funda√ß√£o'] = pd.to_numeric(df['Ano de Funda√ß√£o'], errors='coerce')
    return df

# Fun√ß√£o para o chat interagir com o modelo de IA
def perguntar_ao_modelo(pergunta, contexto_dados):
    # Configura o modelo de IA (Gemini do Google) usando os Secrets
    try:
        # Para deploy no Streamlit Cloud
        genai.configure(api_key=st.secrets["GEMINI_API_KEY"])
    except KeyError:
        # Para rodar localmente, busca do arquivo .env
        genai.configure(api_key=os.getenv("GEMINI_API_KEY"))

    model = genai.GenerativeModel('gemini-pro')
    prompt = f"""
    Voc√™ √© um assistente especialista em an√°lise de startups para a NVIDIA.
    Responda √† pergunta do usu√°rio usando apenas os dados fornecidos abaixo.
    Seja claro, direto e, se a resposta contiver uma lista, formate-a como uma tabela em Markdown. N√£o mostre c√≥digo.
    Dados:
    {contexto_dados}
    Pergunta:
    {pergunta}
    """
    resposta = model.generate_content(prompt)
    return resposta.text

# --- IN√çCIO DA INTERFACE GR√ÅFICA ---

st.title("ü§ñ NVIDIA Inception: An√°lise de Startups na Am√©rica Latina")

# Carrega os dados uma vez
try:
    df = carregar_dados()

    # Cria a estrutura de Abas
    tab1, tab2 = st.tabs(["üìä Dashboard de An√°lise", "üí¨ Chat Interativo"])

    # --- Conte√∫do da Aba 1: DASHBOARD ---
    with tab1:
        st.header("Vis√£o Geral do Ecossistema")
        col1, col2, col3, col4 = st.columns(4)
        col1.metric("Total de Startups Mapeadas", f"{len(df)}")
        col2.metric("Pa√≠s com Mais Startups", df['Pa√≠s'].mode()[0] if not df['Pa√≠s'].empty else "N/A")
        col3.metric("Setor Mais Comum", df['Setor de Atua√ß√£o'].mode()[0] if not df['Setor de Atua√ß√£o'].empty else "N/A")
        col4.metric("Fundada Mais Recentemente", f"{int(df['Ano de Funda√ß√£o'].max())}" if not df['Ano de Funda√ß√£o'].dropna().empty else "N/A")

        # Gr√°ficos...
        col_graf1, col_graf2 = st.columns(2)
        with col_graf1:
            st.write("##### Startups por Pa√≠s")
            fig_pais = px.bar(df['Pa√≠s'].value_counts().reset_index(), x='Pa√≠s', y='count', labels={'count':'N√∫mero de Startups'})
            st.plotly_chart(fig_pais, use_container_width=True)
        with col_graf2:
            st.write("##### Startups por Setor")
            fig_setor = px.pie(df['Setor de Atua√ß√£o'].value_counts().reset_index(), names='Setor de Atua√ß√£o', values='count')
            st.plotly_chart(fig_setor, use_container_width=True)

        st.header("Explore os Dados")
        st.dataframe(df) # Exibe a tabela completa

    # --- Conte√∫do da Aba 2: CHAT ---
    with tab2:
        st.header("Converse com os Dados")
        st.write("Fa√ßa perguntas em linguagem natural sobre o ecossistema de startups.")

        # Inicializa o hist√≥rico do chat
        if "messages" not in st.session_state:
            st.session_state.messages = []

        # Exibe as mensagens do hist√≥rico
        for message in st.session_state.messages:
            with st.chat_message(message["role"]):
                st.markdown(message["content"])

        # Input do usu√°rio
        if prompt := st.chat_input("Ex: Quais startups do Brasil usam IA Generativa?"):
            # Adiciona a mensagem do usu√°rio ao hist√≥rico e exibe
            st.session_state.messages.append({"role": "user", "content": prompt})
            with st.chat_message("user"):
                st.markdown(prompt)

            # Gera e exibe a resposta do assistente
            with st.chat_message("assistant"):
                with st.spinner("Analisando..."):
                    contexto_dados_string = df.to_string(index=False)
                    resposta = perguntar_ao_modelo(prompt, contexto_dados_string)
                    st.markdown(resposta)
            
            # Adiciona a resposta do assistente ao hist√≥rico
            st.session_state.messages.append({"role": "assistant", "content": resposta})

except Exception as e:
    st.error(f"Erro ao carregar os dados. Verifique a conex√£o com a planilha e suas credenciais. Detalhes: {e}")